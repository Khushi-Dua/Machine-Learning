{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "114e75dd",
   "metadata": {},
   "source": [
    "# Detecting Outliers with the IQR MethodðŸ“Š\n",
    "Hey there, data explorer! ðŸŒŸ Now that you've gotten comfortable with datasets, letâ€™s dive into how we can identify and handle outliers using the IQR method. Outliers can skew your analysis, but with this technique, we can easily spot and deal with them to keep our data clean and accurate! Let's get started with understanding how the Interquartile Range (IQR) helps us find those unexpected values in our dataset. ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be8fdef",
   "metadata": {},
   "source": [
    "# AIM:\n",
    "## 1. Load a dataset with missing values and noise.\n",
    "## 2. Handle missing values by imputation (mean, median) or removal.\n",
    "## 3. Remove noise by filtering outliers using Z-score or IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dafc75bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809cf0df",
   "metadata": {},
   "source": [
    "## 1.Load a dataset with missing values and noise\n",
    "- **Noise in a dataset** refers to random, irrelevant, or erroneous data that does not contribute meaningfully to the analysis or prediction. It can arise from various sources and can negatively affect the performance of machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59f0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "data = {\n",
    " 'A': np.random.randn(100),\n",
    " 'B': np.random.randn(100),\n",
    " 'C': np.random.randn(100)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f52fca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# introduce missing values\n",
    "data['A'][::10] = np.nan \n",
    "data['B'][::15] = np.nan \n",
    "data['C'][::20] = np.nan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9468a965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fa031a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset with missing values and noise:\n",
      "           A         B         C\n",
      "0        NaN       NaN       NaN\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "10       NaN  1.867559  0.910179\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "15  0.333674       NaN -0.410050\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "18  0.313068  0.614079  2.259309\n",
      "19 -0.854096  0.922207 -0.042257\n"
     ]
    }
   ],
   "source": [
    "print(\"Original dataset with missing values and noise:\")\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d0aa81",
   "metadata": {},
   "source": [
    "## 2. Handle missing values by imputation (mean, median) or removal\n",
    "**Imputation** refers to the process of filling in missing or incomplete data in a dataset. It is commonly used in data preprocessing to handle **missing values** before applying machine learning algorithms, as many models cannot handle null or missing values directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1643815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after mean imputation:\n",
      "           A         B         C\n",
      "0   0.110294  0.069359 -0.028013\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "10  0.110294  1.867559  0.910179\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "15  0.333674  0.069359 -0.410050\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "18  0.313068  0.614079  2.259309\n",
      "19 -0.854096  0.922207 -0.042257\n"
     ]
    }
   ],
   "source": [
    "# Imputation by mean\n",
    "df_mean_imputed = df.fillna(df.mean())\n",
    "print(\"\\nDataset after mean imputation:\")\n",
    "print(df_mean_imputed.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e191452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after median imputation:\n",
      "           A         B         C\n",
      "0   0.124294  0.017479 -0.024326\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "10  0.124294  1.867559  0.910179\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "15  0.333674  0.017479 -0.410050\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "18  0.313068  0.614079  2.259309\n",
      "19 -0.854096  0.922207 -0.042257\n"
     ]
    }
   ],
   "source": [
    "# Imputation by median\n",
    "df_median_imputed = df.fillna(df.median())\n",
    "print(\"\\nDataset after median imputation:\")\n",
    "print(df_median_imputed.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff6dd7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after removing rows with missing values:\n",
      "           A         B         C\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "18  0.313068  0.614079  2.259309\n",
      "19 -0.854096  0.922207 -0.042257\n",
      "21  0.653619 -1.099401 -0.345982\n",
      "22  0.864436  0.298238 -0.463596\n",
      "23 -0.742165  1.326386  0.481481\n"
     ]
    }
   ],
   "source": [
    "# Removal of rows with missing values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataset after removing rows with missing values:\")\n",
    "print(df_dropped.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3956e5b7",
   "metadata": {},
   "source": [
    "## 3. Remove noise by filtering outliers using Z-score or IQR method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b9ee0d",
   "metadata": {},
   "source": [
    "### Using Z-Score method\n",
    "**A Z-score measures how many standard deviations a data point is from the mean of a dataset.** It is used primarily for normalizing or standardizing data, and for detecting outliers.Itâ€™s calculated using:\n",
    "\n",
    "$$\n",
    "Z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- **x** is the data point,\n",
    "\n",
    "- **Î¼** is the mean, and\n",
    "\n",
    "- **Ïƒ** is the standard deviation.\n",
    "\n",
    "- **Z = 0:** The value is at the mean.\n",
    "\n",
    "- **Z > 0:** The value is above the mean.\n",
    "\n",
    "- **Z < 0:** The value is below the mean.\n",
    "\n",
    "**Normalization**: Z-score scales features to have a mean of 0 and a standard deviation of 1, improving model performance, especially for models sensitive to scale.\n",
    "\n",
    "**Outlier Detection**: Z-scores above Â±3 are considered outliers, as they are far from the mean.\n",
    "\n",
    "Z-scores help compare data across different datasets and detect outliers\n",
    "\n",
    "- `np.abs(stats.zscore(...))`: Computes the absolute Z-scores for the dataset.\n",
    "- `(z_scores < 3).all(axis=1)`: Filters rows where all feature Z-scores are below 3 (no outliers).\n",
    "- `df_mean_imputed[...]`: Selects rows without outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9edd3b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after removing outliers using Z-score method:\n",
      "           A         B         C\n",
      "0   0.110294  0.069359 -0.028013\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "10  0.110294  1.867559  0.910179\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "15  0.333674  0.069359 -0.410050\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "18  0.313068  0.614079  2.259309\n",
      "19 -0.854096  0.922207 -0.042257\n"
     ]
    }
   ],
   "source": [
    "z_scores = np.abs(stats.zscore(df_mean_imputed))\n",
    "df_no_outliers_zscore = df_mean_imputed[(z_scores < 3).all(axis=1)]\n",
    "print(\"\\nDataset after removing outliers using Z-score method:\")\n",
    "print(df_no_outliers_zscore.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bf9f37",
   "metadata": {},
   "source": [
    "### Using IQR Method \n",
    "\n",
    "The **IQR (Interquartile Range)** method is used to detect **outliers** by calculating the range between the first quartile (Q1) and third quartile (Q3) of a dataset:\n",
    "1. IQR = Q3-Q1\n",
    "2. Lower Bound = Q1 - 1.5 Ã— IQR\n",
    "3. Upper Bound = Q3 + 1.5 Ã— IQR\n",
    "\n",
    "Outliers are values below the lower bound or above the upper bound.\n",
    "\n",
    "Itâ€™s effective for identifying outliers in skewed or non-normal data.\n",
    "\n",
    "- `(df_mean_imputed < ... | df_mean_imputed > ...)`: Creates a boolean mask where True represents outliers.\n",
    "- `.any(axis=1)`: Checks if any feature in a row is an outlier (across columns).\n",
    "- `~`: Inverts the boolean mask, keeping rows where no feature is an outlier.\n",
    "- This results in a dataframe (`df_no_outliers_iqr`) that contains only rows where no feature exceeds the outlier thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf355e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset after removing outliers using IQR method:\n",
      "           A         B         C\n",
      "0   0.110294  0.069359 -0.028013\n",
      "1   0.400157 -1.347759 -0.239379\n",
      "2   0.978738 -1.270485  1.099660\n",
      "3   2.240893  0.969397  0.655264\n",
      "4   1.867558 -1.173123  0.640132\n",
      "5  -0.977278  1.943621 -1.616956\n",
      "6   0.950088 -0.413619 -0.024326\n",
      "7  -0.151357 -0.747455 -0.738031\n",
      "8  -0.103219  1.922942  0.279925\n",
      "9   0.410599  1.480515 -0.098150\n",
      "10  0.110294  1.867559  0.910179\n",
      "11  1.454274  0.906045  0.317218\n",
      "12  0.761038 -0.861226  0.786328\n",
      "13  0.121675  1.910065 -0.466419\n",
      "14  0.443863 -0.268003 -0.944446\n",
      "15  0.333674  0.069359 -0.410050\n",
      "16  1.494079  0.947252 -0.017020\n",
      "17 -0.205158 -0.155010  0.379152\n",
      "19 -0.854096  0.922207 -0.042257\n",
      "20  0.110294  0.376426 -0.028013\n"
     ]
    }
   ],
   "source": [
    "Q1 = df_mean_imputed.quantile(0.25)\n",
    "Q3 = df_mean_imputed.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_no_outliers_iqr = df_mean_imputed[~((df_mean_imputed < (Q1 - 1.5 * IQR)) |\n",
    "(df_mean_imputed > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "print(\"\\nDataset after removing outliers using IQR method:\")\n",
    "print(df_no_outliers_iqr.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97addf81",
   "metadata": {},
   "source": [
    "## When to Use Z-Score:\n",
    "- **Normal Distribution**: Best for data that is approximately normally distributed.\n",
    "- **Feature Scaling**: Useful for standardizing features (mean = 0, SD = 1), especially in models like KNN, SVM, and Logistic Regression.\n",
    "- **Outlier Detection**: Detects outliers based on how far data points are from the mean (Z-score > 3).\n",
    "\n",
    "## When to Use IQR:\n",
    "- **Non-Normal or Skewed Data**: Best for data that is skewed or non-normal.\n",
    "- **Robust Outlier Detection**: Less sensitive to extreme values, detects outliers using quartiles (1.5 * IQR rule).\n",
    "- **Non-Parametric**: Doesn't assume normality, works well with small or non-normal datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
